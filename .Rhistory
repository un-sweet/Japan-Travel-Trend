getwd()
hekp.start()
help.start()
13+7
a <- 13+7
a
ls()
b <- a-5
c <- b*5
d <- c/15
a, b, c, d
a b c d
a
x <- c(1,3,5,10)
c(x, a, b, c, d)
x
c(1, 2, 3, 4, 5, 6) + c(5, 10)
# QD
odd_num <- c(2,4,6,8,10)
# QB
B <- A*10
ls()
A
A <- 5
A
odd_num
Budget
odd_num
A <- 5
B <- A*10
Budget <- B/7
odd_num <- c(2,4,6,8,10)
# QA
A <- 5
A
# QB
B <- A*10
B
# QC
Budget <- B/7
Budget
# QD
odd_num <- c(2,4,6,8,10)
odd_num
A <- 5
A <- 5
# QA
A <- 5
A
# QA
A <- 5
A
# QB
B <- A*10
B
# QC
Budget <- B/7
Budget
# QD
odd_num <- c(2,4,6,8,10)
odd_num
z
# Q1
x <- 1:50
# Q2
y <- seq(51,100)
# Q3
z <- seq(200,190)
x
y
z
# QC
# Q1
a <- seq(1, 20, by=pi)
a
# Q2
w <- seq(1,5, length.out=20)
w
# Q3
round(w, digits=3)
place <- c("Tokyo", "Paris", "New York", "Bejing")
place
place == "Paris"
vect <- 1:20
vect
dim(vect)
## Copy and paste following syntax in Console
## Rmarkdown
install.packages("rmarkdown")
## Tex (For PDF output format)
install.packages("tinytex")
tinytex::install_tinytex()
knitr::opts_chunk$set(echo = TRUE)
x <- seq(1, 4)
y <- seq(1, 5)
z <- x+y
z
x <- seq(1, 4)
y <- seq(1, 5)
z <- x+y
z[4]
x <- seq(1, 4)
y <- seq(1, 5)
z <- x+y
z[5]
dim(vect) <- c(5, 4)
matrixA <- matrix(1:20, nrow=5, byrow=TRUE)
colnames(matrixA) <- c("individual", "age", "weight", "height")
matrixA
matrixA <- matrix(1:20, nrow=5, byrow=FALSE)
colnames(matrixA) <- c("individual", "age", "weight", "height")
matrixA
x <- seq(1, 4)
y <- seq(1, 5)
z <- x+y
z[5]
seq(1, 10, length.out=13)
t <- seq(1, 100, by=13.79)
print(t)
devtools::install_github(‘yihui/tinytex’)
## Copy and paste following syntax in Console
## Rmarkdown
install.packages("rmarkdown")
## Tex (For PDF output format)
install.packages("tinytex")
tinytex::install_tinytex()
install.packages("tinytex")
install.packages("rmarkdown")
vec1 <- seq(from=3, to=50, by=4)
vec2 <- c(5, 1, 2, 4, 3)
print(vec1)
vec1 <- seq(from=3, to=50, by=4)
vec2 <- c(5, 1, 2, 4, 3)
print(vec1)
print(vec2)
mean(vec1)
mean(vec1)
median(vec1)
var(vec1)
mean(vec2)
median(vec2)
var(vec2)
# Set the seed for reproducibility
set.seed(123)
# Generate a vector of 100 random ages between 0 and 110
ages <- sample(0:110, 100, replace = TRUE)
# Create an empty vector to store the mean ages
mean.age <- vector("numeric", 10)
# Perform the sampling and calculate means
for (i in 1:10) {
# Randomly select 20 people
sample_people <- sample(ages, 20)
# Calculate the mean age of the selected people
mean_age <- mean(sample_people)
# Store the mean age in the vector
mean.age[i] <- mean_age
}
# Print the vector of mean ages
print(mean.age)
library(ggplot2)
birthday <- function(n) {
p <- 1 - permut(365, n) / (365^n)
return(p)
}
# Calculate the probabilities for different numbers of people
n_people <- 1:100
probabilities <- sapply(n_people, birthday)
# permutations
permut <- function(n, r) {
if (r > n) {
stop("Error: r should be less than or equal to n.")
}
numerator <- factorial(n)
denominator <- factorial(n - r)
permutations <- numerator / denominator
return(permutations)
}
# Q1
n <- 4
r <- 4
ways <- permut(n, r)
print(ways)
# Q2
n <- 52
r <- 13
ways <- permut(n, r)
print(ways)
# Q3
birthday <- function(n) {
p <- 1 - permut(365, n) / (365^n)
return(p)
}
# Calculate the probabilities for different numbers of people
n_people <- 1:100
probabilities <- sapply(n_people, birthday)
# Find the minimum number of people where the probability exceeds 0.5
min_n <- min(n_people[probabilities > 0.5])
# Print the minimum number of people
print(min_n)
# Plot the results
data <- data.frame(n_people, probabilities)
ggplot(data, aes(x = n_people, y = probabilities)) +
geom_line() +
geom_hline(yintercept = 0.5, color = "red", linetype = "dashed") +
xlab("Number of People") +
ylab("Probability") +
ggtitle("Probability of at Least Two People Having the Same Birthday") +
theme_minimal()
# variance
variance_custom <- function(x) {
n <- length(x)
mean <- mean_custom(x)
variance <- sum((x - mean)^2) / (n - 1)
return(variance)
}
# Set the seed for reproducibility
set.seed(123)
ages <- sample(0:110, 100, replace = TRUE)
mean.age <- vector("numeric", 10)
for (i in 1:10) {
sample_people <- sample(ages, 20)
mean_age <- mean(sample_people)
mean.age[i] <- mean_age
}
print(mean.age)
# Plot the results
data <- data.frame(n_people, probabilities)
ggplot(data, aes(x = n_people, y = probabilities)) +
geom_line() +
geom_hline(yintercept = 0.5, color = "red", linetype = "dashed") +
xlab("Number of People") +
ylab("Probability") +
ggtitle("Probability of at Least Two People Having the Same Birthday") +
theme_minimal()
df <- data.frame(mean.age)
df
# Set the seed for reproducibility
set.seed(123)
ages <- sample(0:110, 100, replace = TRUE)
mean.age <- vector("numeric", 10)
for (i in 1:10) {
sample_people <- sample(ages, 20)
mean_age <- mean(sample_people)
mean.age[i] <- mean_age
}
df <- data.frame(mean.age)
df
ggplot(data=df, aes(x = c(1:10), y = mean.age)) +
geom_point(color="lightblue", size=5) +
scale_x_continuous(breaks = c(1:10))+
scale_y_continuous(limits=c(1:110))+
xlab("iteration") +
ylab("mean age of random samples") +
ggtitle("Survey1") +
theme_minimal()
ggplot(data=df, aes(x = c(1:10), y = mean.age)) +
geom_point(color="lightblue", size=5) +
scale_x_continuous(breaks = c(1:10))+
scale_y_continuous(limits=c(0,110))+
xlab("iteration") +
ylab("mean age of random samples") +
ggtitle("Survey1") +
theme_minimal()
# permutations
permut <- function(n, r) {
if (r > n) {
stop("Error: r should be less than or equal to n.")
}
numerator <- factorial(n)
denominator <- factorial(n - r)
permutations <- numerator / denominator
return(permutations)
}
# Q1
n <- 4
r <- 4
ways <- permut(n, r)
print(ways)
# Q2
n <- 52
r <- 13
ways <- permut(n, r)
print(ways)
birthday <- function(k){
logdenom <- k * log(365)+lfactorial(365-k) # log denominator
lognumber <- lfactorial(365) # log numerator
## P(at least two have the same bday) =1 -p(nobody has the same birthday)
pr <- 1 - exp(lognumber - logdenom) # transform back
return(pr)
}
k <- 1:50
bday <- birthday(k) # call the function
names(bday) <- k
plot(k, bday, rlab="Number of people", xlim = c(0,50), ylim=c(0,1),
ylab="Probability thay at least two\n people have the same birthday")
abline(h=05, v=23, col=c("red", "blue"))
birthday <- function(k){
logdenom <- k * log(365)+lfactorial(365-k) # log denominator
lognumber <- lfactorial(365) # log numerator
## P(at least two have the same bday) =1 -p(nobody has the same birthday)
pr <- 1 - exp(lognumber - logdenom) # transform back
return(pr)
}
k <- 1:50
bday <- birthday(k) # call the function
names(bday) <- k
plot(k, bday, xlab="Number of people", xlim = c(0,50), ylim=c(0,1),
ylab="Probability thay at least two\n people have the same birthday")
abline(h=05, v=23, col=c("red", "blue"))
Sys.setenv(LANG = "en")
install.packages('devtools', repos='http://cran.us.r-project.org')
devtools::install_github("quanteda/quanteda.corpora") #worng
install.packages('profvis', repos = NULL, type = 'source')
devtools::install_github("quanteda/quanteda.textmodels")
devtools::install_version("quanteda.textstats", version = "0.94", repos = "http://cran.us.rproject.org"
devtools::install_version("quanteda.textstats", version = "0.94", repos = "http://cran.us.rproject.org")
devtools::install_github("quanteda/quanteda.textmodels")
Sys.setenv(LANG = "en")
devtools::install_version("quanteda.textstats", version = "0.94", repos = "http://cran.us.rproject.org")
devtools::install_github("rstudio/profvis")
install.packages('devtools', repos='http://cran.us.r-project.org')#worng
devtools::install_github("quanteda/quanteda.textmodels")
devtools::install_github("quanteda/quanteda.corpora")
install.packages('quanteda', repos='http://cran.us.r-project.org')
install.packages('quanteda.textstats', repos='http://cran.us.rproject.org')
install.packages('quanteda.textplots', repos='http://cran.us.rproject.org')
install.packages('readtext', repos='http://cran.us.r-project.org')
install.packages('devtools', repos='http://cran.us.r-project.org')#worng
remove.packages("profvis")
chooseCRANmirror(graphics = FALSE)
install.packages('devtools', repos='http://cran.us.r-project.org')#worng
devtools::install_github("rstudio/profvis")
install.packages('profvis', repos = NULL, type = 'win.binary')
Sys.getlocale()
Sys.setlocale("LC_MESSAGES", "en_US.UTF-8")
Sys.setlocale("LC_MESSAGES", "en_US.UTF-8")
Sys.setlocale(category = "LC_ALL", locale = "English_United States.1252")
Sys.setenv(LANGUAGE = "en")
Sys.setlocale("LC_MESSAGES", "en_US.UTF-8")
install.packages("stm", repos='http://cran.us.r-project.org')
install.packages('keyATM', repos='http://cran.us.r-project.org’)
install.packages('keyATM', repos='http://cran.us.r-project.org’)
install.packages('keyATM', repos='http://cran.us.r-project.org’)
install.packages('keyATM', repos='http://cran.us.r-project.org')
install.packages('ranger', repos='http://cran.us.r-project.org')
install.packages('e1071', repos='http://cran.us.r-project.org’)
Sys.setenv(LANGUAGE = "en")
getwd()
Sys.setlocale("LC_ALL", 'en_GB.UTF-8')
Sys.setenv(LANG = "en_GB.UTF-8")
library(tidyverse)
library(quanteda)
library(quanteda.textstats)
library(quanteda.textmodels)
library(quanteda.textplots)
library(corrplot)
# I'll get you started...
Sys.setlocale("LC_ALL", 'en_GB.UTF-8')
Sys.setenv(LANG = "en_GB.UTF-8")
library(tidyverse)
library(quanteda)
library(quanteda.textstats)
library(quanteda.textmodels)
library(quanteda.textplots)
library(corrplot)
budget_speeches <- data_corpus_irishbudget2010
summary(budget_speeches)
# task 1 Prepare this corpus for analysis
docvars(budget_speeches)
budget_speeches <- data_corpus_irishbudget2010
budget_speeches$FullName <- paste(budget_speeches$foren,
budget_speeches$name)
docvars(budget_speeches)
speech_tokens <- budget_speeches %>%
tokens(remove_punct = TRUE, remove_symbols = TRUE,
remove_numbers = TRUE, remove_separators = TRUE) %>%
tokens_remove(stopwords(language = "en", source = "marimo")) %>%
tokens_wordstem(language = "en")
head(speech_tokens)
speech_dfm <- dfm(speech_tokens)
speech_dfm
corrplot(as.matrix(speech_simil), method = "number", type = "lower")
speech_simil <- textstat_simil(speech_dfm, margin = "documents", method = "cosine")
speech_simil
corrplot(as.matrix(speech_simil), method = "number", type = "lower")
corrplot(as.matrix(speech_simil), method = "number", type = "lower",
is.corr = FALSE, col.lim = c(0.4, 1.0), col = COL1("Blues", 12))
corrplot(as.matrix(speech_simil), method = "number", type = "lower",
is.corr = FALSE, col.lim = c(0.2, 1.0), col = COL1("Blues", 12))
corrplot(as.matrix(speech_simil), method = "number", type = "lower",
is.corr = FALSE, col.lim = c(0.3, 1.0), col = COL1("Blues", 12))
corrplot(as.matrix(speech_simil), method = "number", type = "lower",
is.corr = FALSE, col.lim = c(0.2, 1.0), col = COL1("Blues", 12))
corrplot(as.matrix(speech_simil), method = "number", type = "lower",
is.corr = FALSE, col.lim = c(0.25, 1.0), col = COL1("Blues", 12))
corrplot(as.matrix(speech_simil), method = "color", type = "lower")
corrplot(as.matrix(speech_simil), method = "color", type = "lower",
is.corr = FALSE, col.lim = c(0.2, 1.0), col = COL1("Blues", 12))
corrplot(as.matrix(speech_simil), method = "color", type = "lower")
corrplot(as.matrix(speech_simil), method = "color", type = "lower",
is.corr = FALSE, col.lim = c(0.2, 1.0), col = COL1("Blues", 12))
summary(speech_dfm)
# 4) Finally: the two biggest parties in Ireland at this time were Fianna
#    Fail (FF) and Fine Gael (FG). Create a Word Cloud which compares the
#    terminology used in the speeches of these two parties.
speech_dfm
# 4) Finally: the two biggest parties in Ireland at this time were Fianna
#    Fail (FF) and Fine Gael (FG). Create a Word Cloud which compares the
#    terminology used in the speeches of these two parties.
docvars(speech_dfm)
summary(speech_dfm)
FF_speech_dfm <- speech_dfm %>% filter(party == "FF")
library(dplyr)
FF_speech_dfm <- speech_dfm %>% filter(party == "FF")
FF_speech_dfm <- subset(speech_dfm, docvars(speech_dfm)$party == "FF")
FF_speech_dfm <- speech_dfm[docvars(speech_dfm)$party == "FF", ]
FF_speech_dfm
FG_speech_dfm <- speech_dfm[docvars(speech_dfm)$party == "FG", ]
FF_speech_dfm
FG_speech_dfm
# 3) Using the Wordfish algorithm, scale these documents and place them
#    on a graph relative to one another.
#    This graph should group the speakers by Party.
docvars(speech_dfm)
corrplot(as.matrix(speech_simil), method = "color", type = "lower")
corrplot(as.matrix(speech_simil), method = "color", type = "lower",
is.corr = FALSE, col.lim = c(0.2, 1.0), col = COL1("Blues", 12))
# 3) Using the Wordfish algorithm, scale these documents and place them
#    on a graph relative to one another.
#    This graph should group the speakers by Party.
docvars(speech_dfm)
speech_wf <- textmodel_wordfish(speech_dfm, dir = c(10, 13))
textplot_scale1d(speech_wf)
textplot_scale1d(speech_wf, groups = docvars(speech_wf, "party"))
textplot_scale1d(speech_wf, groups = docvars(speech_dfm, "party"))
docvars(speech_dfm)
speech_wf <- textmodel_wordfish(speech_dfm, dir = c(10, 1))
# plot the graph group by party
textplot_scale1d(speech_wf, groups = docvars(speech_dfm, "party"))
docvars(speech_dfm)
speech_wf <- textmodel_wordfish(speech_dfm, dir = c(10, 13))
# plot the graph group by party
textplot_scale1d(speech_wf, groups = docvars(speech_dfm, "party"))
docvars(speech_dfm)
inaug_dfm %>%
dfm_subset(party == "FF"|"FG") %>%
dfm_group(groups = party) %>%
textplot_wordcloud(min_count = 20, comparison = TRUE,
color = RColorBrewer::brewer.pal(3, "Dark2"))
set.seed(1314)
speech_dfm %>%
dfm_subset(party == "FF"|"FG") %>%
dfm_group(groups = party) %>%
textplot_wordcloud(min_count = 20, comparison = TRUE,
color = RColorBrewer::brewer.pal(3, "Dark2"))
speech_dfm %>%
dfm_subset(party %in% c("FF", "FG")) %>%
dfm_group(groups = party) %>%
textplot_wordcloud(min_count = 20, comparison = TRUE,
color = RColorBrewer::brewer.pal(3, "Dark2"))
speech_dfm %>%
dfm_subset(party %in% c("FF", "FG")) %>%
dfm_group(groups = party) %>%
textplot_wordcloud(min_count = 20, comparison = TRUE,
color = RColorBrewer::brewer.pal(3, "Dark2"),
max_size = 1)
speech_dfm %>%
dfm_subset(party %in% c("FF", "FG")) %>%
dfm_group(groups = party) %>%
textplot_wordcloud(min_count = 20, comparison = TRUE,
color = RColorBrewer::brewer.pal(3, "Dark2"),
max_size = 20)
speech_dfm %>%
dfm_subset(party %in% c("FF", "FG")) %>%
dfm_group(groups = party) %>%
textplot_wordcloud(min_count = 20, comparison = TRUE,
color = RColorBrewer::brewer.pal(3, "Dark2"),
max_size = 10)
speech_dfm %>%
dfm_subset(party %in% c("FF", "FG")) %>%
dfm_group(groups = party) %>%
textplot_wordcloud(min_count = 20, comparison = TRUE,
color = RColorBrewer::brewer.pal(3, "Dark2"),
max_size = 8)
sum(26.52, 28.04, 27.06, 25.89, 25.22, 25.56, 26.36, 24.67, 27.78, 27.27)/10
sum(26.52, 28.04, 27.06, 25.89, 25.22, 25.56, 26.36, 24.67, 27.78, 27.27)/10
var(26.52, 28.04, 27.06, 25.89, 25.22, 25.56, 26.36, 24.67, 27.78, 27.27)/10
sum(26.52, 28.04, 27.06, 25.89, 25.22, 25.56, 26.36, 24.67, 27.78, 27.27)/10
var(26.52, 28.04, 27.06, 25.89, 25.22, 25.56, 26.36, 24.67, 27.78, 27.27)
data <- c(26.52, 28.04, 27.06, 25.89, 25.22, 25.56, 26.36, 24.67, 27.78, 27.27)
var(data)
var(data)
var(data)* (n-1) / n
var(data)* (9) / 10
library(installr)
updateR()
getwd()
Sys.setlocale("LC_ALL", 'en_GB.UTF-8')
Sys.setenv(LANG = "en_GB.UTF-8")
setwd("./../Desktop/Political Text/Final")
library(readxl)
# Read data
data <- read_excel("./../Data_1/data.xlsx")
data4 <- read_excel("./../Data_2/data4.xlsx")
